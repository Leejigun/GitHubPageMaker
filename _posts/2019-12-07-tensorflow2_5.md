---
layout: post
current: post
navigation: True
title:  "[tensoflow 2.0] 5. 머신러닝 최적화"
date:   2019-12-07 00:00:01
cover: assets/images/ml/tensorflow2_5/background.png
description: 분류(Classification) 프로젝트
tags: [ ml ]
class: post-template
subclass: 'post tag-getting-started'
author: jglee
---
# 머신러닝 최적화

## Overshooting

 경사 하강법을 사용하면서 우리는 조금 조금씩 아래로 내려오면서 수렴하는 지점을 찾아 나간다. 근데 만약 learning rate 값이 너무 크면 수렴하는 지점을 넘어가게 된다.

아래와 같이 learning rate가 너무 커 수렴값을 마구잡이로 넘어다니는 현상을 Overshooting이라 한다.

![5/Untitled.png](assets/images/ml/tensorflow2_5/Untitled.png)

## Normalization

![5/Untitled%201.png](assets/images/ml/tensorflow2_5/Untitled 1.png)

 앞서 머신러닝 데이터를 가공하는 과정에서 스케일을 줄였었다. 스케일 범위가 너무 크면 노이즈 데이터가 생성되거나 오버피팅될 가능성이 높다.

## Overfitting

![5/Untitled%202.png](assets/images/ml/tensorflow2_5/Untitled 2.png)

학습 세트에 과도하게 맞춰지면 일반적인 경우에 대한 결과값을 얻을 수 없다.

우리가 짜는 모델은 일반적인 경우에 해당하는 보편적 예측을 위한 모델이지 학습 데이터를 읽어주는 모델이 아니다.

학습 데이터에 대한 정확성과 테스트 데이터에 대한 정확성이 너무 차이난다면 과적합 되었다고 볼 수 있다.
